/*
  一键将本地 SQLite 数据迁移到 PostgreSQL
  使用方式：
    DATABASE_URL="<你的PG连接串>" node scripts/migrate-sqlite-to-pg.js

  注意：
  - 默认会 TRUNCATE 目标 PG 表（清空后重新导入）。如需保留，设置环境变量 MIGRATE_TRUNCATE=false
  - 该脚本会自动创建 PG 表结构（与 SQLite 基本一致），主键为 GENERATED BY DEFAULT AS IDENTITY，允许显式插入 id
  - 导入完成后会 reset 序列到最大 id + 1
*/

const path = require('path');
const fs = require('fs');
const sqlite3 = require('sqlite3').verbose();
const { Pool } = require('pg');
const config = require('../config');

const DATABASE_URL = process.env.DATABASE_URL;
if (!DATABASE_URL) {
  console.error('缺少环境变量 DATABASE_URL，请提供 PostgreSQL 连接串');
  process.exit(1);
}

const shouldTruncate = String(process.env.MIGRATE_TRUNCATE || 'true').toLowerCase() !== 'false';
const forceMigrate = String(process.env.MIGRATE_FORCE || 'false').toLowerCase() === 'true';

const sqlitePath = path.resolve(config.DB_PATH);
if (!fs.existsSync(sqlitePath)) {
  console.error(`未找到 SQLite 数据库文件: ${sqlitePath}`);
  process.exit(1);
}

const pg = new Pool({ connectionString: DATABASE_URL, ssl: process.env.PGSSL === 'false' ? false : { rejectUnauthorized: false } });
const sqldb = new sqlite3.Database(sqlitePath);

async function query(text, params = []) {
  return pg.query(text, params);
}

async function createPgSchema() {
  const ddl = `
  CREATE TABLE IF NOT EXISTS users (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    username TEXT UNIQUE NOT NULL,
    email TEXT UNIQUE NOT NULL,
    password TEXT NOT NULL,
    company_name TEXT,
    contact_name TEXT,
    phone TEXT,
    role TEXT DEFAULT 'client',
    created_at TIMESTAMPTZ DEFAULT now(),
    updated_at TIMESTAMPTZ DEFAULT now()
  );

  CREATE TABLE IF NOT EXISTS products (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    sku TEXT UNIQUE NOT NULL,
    name TEXT NOT NULL,
    category TEXT NOT NULL,
    description TEXT,
    unit TEXT DEFAULT 'piece',
    safety_stock INTEGER DEFAULT 0,
    created_at TIMESTAMPTZ DEFAULT now(),
    updated_at TIMESTAMPTZ DEFAULT now()
  );

  CREATE TABLE IF NOT EXISTS inventory (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    product_id BIGINT NOT NULL REFERENCES products(id),
    current_stock INTEGER DEFAULT 0,
    reserved_stock INTEGER DEFAULT 0,
    available_stock INTEGER DEFAULT 0,
    last_updated TIMESTAMPTZ DEFAULT now()
  );

  CREATE TABLE IF NOT EXISTS orders (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    order_number TEXT UNIQUE NOT NULL,
    user_id BIGINT NOT NULL REFERENCES users(id),
    customer_name TEXT NOT NULL,
    customer_phone TEXT,
    customer_address TEXT,
    service_type TEXT NOT NULL,
    total_weight DOUBLE PRECISION,
    total_amount DOUBLE PRECISION,
    status TEXT DEFAULT 'pending',
    notes TEXT,
    created_at TIMESTAMPTZ DEFAULT now(),
    updated_at TIMESTAMPTZ DEFAULT now()
  );

  CREATE TABLE IF NOT EXISTS order_items (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    order_id BIGINT NOT NULL REFERENCES orders(id),
    product_id BIGINT NOT NULL REFERENCES products(id),
    quantity INTEGER NOT NULL,
    unit_price DOUBLE PRECISION,
    total_price DOUBLE PRECISION
  );

  CREATE TABLE IF NOT EXISTS inbound_records (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    inbound_number TEXT UNIQUE NOT NULL,
    supplier TEXT NOT NULL,
    product_id BIGINT NOT NULL REFERENCES products(id),
    quantity INTEGER NOT NULL,
    unit_price DOUBLE PRECISION,
    total_amount DOUBLE PRECISION,
    status TEXT DEFAULT 'pending',
    inbound_time TIMESTAMPTZ,
    notes TEXT,
    created_by BIGINT REFERENCES users(id),
    created_at TIMESTAMPTZ DEFAULT now()
  );

  CREATE TABLE IF NOT EXISTS outbound_records (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    outbound_number TEXT UNIQUE NOT NULL,
    order_id BIGINT REFERENCES orders(id),
    customer TEXT NOT NULL,
    product_id BIGINT NOT NULL REFERENCES products(id),
    quantity INTEGER NOT NULL,
    destination TEXT,
    status TEXT DEFAULT 'pending',
    outbound_time TIMESTAMPTZ,
    notes TEXT,
    created_by BIGINT REFERENCES users(id),
    created_at TIMESTAMPTZ DEFAULT now()
  );

  CREATE TABLE IF NOT EXISTS tracking (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    tracking_number TEXT UNIQUE NOT NULL,
    order_id BIGINT REFERENCES orders(id),
    current_status TEXT NOT NULL,
    current_location TEXT,
    estimated_delivery DATE,
    created_at TIMESTAMPTZ DEFAULT now(),
    updated_at TIMESTAMPTZ DEFAULT now()
  );

  CREATE TABLE IF NOT EXISTS tracking_updates (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    tracking_id BIGINT NOT NULL REFERENCES tracking(id),
    status TEXT NOT NULL,
    location TEXT,
    update_time TIMESTAMPTZ DEFAULT now(),
    notes TEXT
  );

  CREATE TABLE IF NOT EXISTS password_resets (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    user_id BIGINT NOT NULL REFERENCES users(id),
    token TEXT UNIQUE NOT NULL,
    expires_at TIMESTAMPTZ NOT NULL,
    created_at TIMESTAMPTZ DEFAULT now()
  );
  `;
  await query(ddl);
}

async function truncateTables() {
  if (!shouldTruncate) return;
  const sql = `TRUNCATE TABLE 
    password_resets,
    tracking_updates,
    tracking,
    order_items,
    outbound_records,
    inbound_records,
    orders,
    inventory,
    products,
    users
  RESTART IDENTITY CASCADE;`;
  await query(sql);
}

async function hasExistingData() {
  try {
    const r = await query('SELECT 1 FROM users LIMIT 1');
    return r && r.rowCount > 0;
  } catch (e) {
    return false;
  }
}

function selectAll(sqlite, table, columns) {
  return new Promise((resolve, reject) => {
    const sql = `SELECT ${columns.join(', ')} FROM ${table}`;
    sqlite.all(sql, [], (err, rows) => {
      if (err) return reject(err);
      resolve(rows || []);
    });
  });
}

async function batchInsert(table, columns, rows) {
  if (!rows.length) return 0;
  const chunkSize = 500;
  let inserted = 0;
  for (let i = 0; i < rows.length; i += chunkSize) {
    const chunk = rows.slice(i, i + chunkSize);
    const values = [];
    const params = [];
    chunk.forEach((row, idx) => {
      const placeholders = columns.map((_, cidx) => `$${idx * columns.length + cidx + 1}`);
      values.push(`(${placeholders.join(',')})`);
      columns.forEach(col => params.push(row[col] === undefined ? null : row[col]));
    });
    const sql = `INSERT INTO ${table} (${columns.join(',')}) VALUES ${values.join(',')} ON CONFLICT (id) DO NOTHING`;
    await query(sql, params);
    inserted += chunk.length;
  }
  return inserted;
}

async function resetSequences() {
  const tables = ['users','products','inventory','orders','order_items','inbound_records','outbound_records','tracking','tracking_updates','password_resets'];
  for (const t of tables) {
    const sql = `SELECT setval(pg_get_serial_sequence('${t}','id'), COALESCE((SELECT MAX(id) FROM ${t}), 0) + 1, false)`;
    await query(sql);
  }
}

async function migrate() {
  console.log('连接 PostgreSQL 成功，开始创建表结构...');
  await createPgSchema();
  const exists = await hasExistingData();
  if (exists && !forceMigrate) {
    console.log('检测到 PostgreSQL 已有数据，跳过迁移（如需强制执行，设置 MIGRATE_FORCE=true）。');
    return;
  }
  if (shouldTruncate) {
    console.log('清空目标表（TRUNCATE）...');
    await truncateTables();
  }

  console.log('读取并迁移数据...');

  const plans = [
    { table: 'users', columns: ['id','username','email','password','company_name','contact_name','phone','role','created_at','updated_at'] },
    { table: 'products', columns: ['id','sku','name','category','description','unit','safety_stock','created_at','updated_at'] },
    { table: 'inventory', columns: ['id','product_id','current_stock','reserved_stock','available_stock','last_updated'] },
    { table: 'orders', columns: ['id','order_number','user_id','customer_name','customer_phone','customer_address','service_type','total_weight','total_amount','status','notes','created_at','updated_at'] },
    { table: 'order_items', columns: ['id','order_id','product_id','quantity','unit_price','total_price'] },
    { table: 'inbound_records', columns: ['id','inbound_number','supplier','product_id','quantity','unit_price','total_amount','status','inbound_time','notes','created_by','created_at'] },
    { table: 'outbound_records', columns: ['id','outbound_number','order_id','customer','product_id','quantity','destination','status','outbound_time','notes','created_by','created_at'] },
    { table: 'tracking', columns: ['id','tracking_number','order_id','current_status','current_location','estimated_delivery','created_at','updated_at'] },
    { table: 'tracking_updates', columns: ['id','tracking_id','status','location','update_time','notes'] },
    { table: 'password_resets', columns: ['id','user_id','token','expires_at','created_at'] },
  ];

  for (const p of plans) {
    try {
      const rows = await selectAll(sqldb, p.table, p.columns);
      if (!rows.length) { console.log(`- ${p.table}: 0 行`); continue; }
      const count = await batchInsert(p.table, p.columns, rows);
      console.log(`- ${p.table}: 导入 ${count} 行`);
    } catch (e) {
      console.warn(`- ${p.table}: 跳过（原因: ${e.message || e}）`);
    }
  }

  console.log('重置序列...');
  await resetSequences();
}

(async () => {
  try {
    await migrate();
    console.log('迁移完成！');
  } catch (e) {
    console.error('迁移失败：', e);
    process.exitCode = 1;
  } finally {
    await pg.end();
    sqldb.close();
  }
})();


